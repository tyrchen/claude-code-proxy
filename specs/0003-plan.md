# Implementation Plan: Claude-to-Gemini Protocol Proxy

## Document Information

- **Project**: claude-code-proxy
- **Version**: 1.0
- **Date**: 2025-11-18
- **Status**: Active
- **Based on**: specs/0002-design-spec.md

---

## 1. Project Overview

### 1.1 Objectives

Build a production-ready protocol translation proxy that allows Claude Code CLI to transparently use Google Gemini models by converting between Claude Messages API and Gemini GenerateContent API protocols.

### 1.2 Success Criteria

- [ ] Claude Code can successfully communicate with Gemini through the proxy
- [ ] Streaming responses work with proper SSE formatting
- [ ] Latency overhead < 10ms (target: < 5ms)
- [ ] Handle edge cases (errors, incomplete streams, malformed JSON)
- [ ] Pass comprehensive test suite (unit + integration)
- [ ] Documentation complete with usage examples

### 1.3 Non-Goals (Phase 1)

- Multi-model support (OpenAI, DeepSeek) - deferred to Phase 2
- Response caching - deferred to Phase 2
- Function/tool calling - deferred to Phase 2
- Image/multimodal support - deferred to Phase 2
- Production deployment infrastructure - deferred to Phase 2

---

## 2. Development Phases

### Phase 1: Foundation (Days 1-3)
**Goal**: Basic project structure and data models

### Phase 2: Request Pipeline (Days 4-6)
**Goal**: Parse Claude requests and transform to Gemini format

### Phase 3: Response Pipeline (Days 7-10)
**Goal**: Parse Gemini streams and generate SSE events

### Phase 4: Pingora Integration (Days 11-13)
**Goal**: Wire everything together with Pingora proxy

### Phase 5: Testing & Refinement (Days 14-16)
**Goal**: Comprehensive testing and bug fixes

### Phase 6: Documentation & Polish (Days 17-18)
**Goal**: Complete documentation and examples

---

## 3. Detailed Task Breakdown

### Phase 1: Foundation (Days 1-3)

#### Day 1: Project Setup & Data Models

**Task 1.1: Initialize Project Structure**
```bash
# Directory structure
mkdir -p src/{models,transform,streaming}
mkdir -p tests/fixtures
mkdir -p examples
mkdir -p benches
```

**Files to create:**
- `src/models/mod.rs`
- `src/models/claude.rs`
- `src/models/gemini.rs`
- `src/transform/mod.rs`
- `src/streaming/mod.rs`
- `src/error.rs`
- `src/config.rs`

**Task 1.2: Define Error Types** (`src/error.rs`)
```rust
use thiserror::Error;

#[derive(Error, Debug)]
pub enum ProxyError {
    #[error("Invalid Claude request: {0}")]
    InvalidClaudeRequest(String),

    #[error("Invalid Gemini response: {0}")]
    InvalidGeminiResponse(String),

    #[error("Transformation error: {0}")]
    TransformationError(String),

    #[error("JSON error: {0}")]
    JsonError(#[from] serde_json::Error),

    #[error("IO error: {0}")]
    IoError(#[from] std::io::Error),
}

pub type Result<T> = std::result::Result<T, ProxyError>;
```

**Task 1.3: Define Claude Data Models** (`src/models/claude.rs`)

Implement all structs from design spec section 3.1.1:
- `ClaudeRequest`
- `ClaudeMessage`
- `ContentType`
- `ContentBlock`
- `SystemPrompt`
- `ClaudeSSEEvent` and related types

**Acceptance Criteria:**
- [ ] All Claude types compile without errors
- [ ] Serde serialization/deserialization works
- [ ] Unit tests for JSON parsing from fixtures

**Task 1.4: Define Gemini Data Models** (`src/models/gemini.rs`)

Implement all structs from design spec sections 3.1.2 and 3.2.2:
- `GeminiRequest`
- `GeminiContent`
- `GeminiPart`
- `GenerationConfig`
- `GeminiStreamChunk`
- `Candidate`
- `UsageMetadata`

**Acceptance Criteria:**
- [ ] All Gemini types compile without errors
- [ ] Serde with camelCase renaming works correctly
- [ ] Unit tests for JSON parsing from fixtures

#### Day 2: Configuration System

**Task 1.5: Configuration Loading** (`src/config.rs`)
```rust
use serde::Deserialize;
use std::env;

#[derive(Debug, Clone, Deserialize)]
pub struct ProxyConfig {
    pub server: ServerConfig,
    pub gemini: GeminiConfig,
}

#[derive(Debug, Clone, Deserialize)]
pub struct ServerConfig {
    pub listen_addr: String,
    pub workers: usize,
}

#[derive(Debug, Clone, Deserialize)]
pub struct GeminiConfig {
    pub api_key: String,
    pub endpoint: String,
}

impl ProxyConfig {
    pub fn from_env() -> Result<Self> {
        // Load from environment variables
    }

    pub fn from_file(path: &str) -> Result<Self> {
        // Load from TOML file
    }
}
```

**Task 1.6: Create Test Fixtures**

Create files in `tests/fixtures/`:
- `claude_request_simple.json` - Basic text message
- `claude_request_with_system.json` - With system prompt
- `claude_request_blocks.json` - With content blocks
- `gemini_response_stream.json` - Sample streaming response
- `gemini_error_response.json` - Error case

**Acceptance Criteria:**
- [ ] Config loads from environment variables
- [ ] Config loads from TOML file
- [ ] Invalid configs return proper errors
- [ ] All test fixtures parse correctly

#### Day 3: Basic Transformation Logic

**Task 1.7: Model Name Mapping** (`src/transform/mod.rs`)
```rust
pub fn map_model_name(claude_model: &str) -> &'static str {
    if claude_model.contains("opus") {
        "gemini-3-pro-preview"
    } else if claude_model.contains("sonnet") {
        "gemini-3-pro-preview"
    } else if claude_model.contains("haiku") {
        "gemini-3-pro-preview"
    } else {
        "gemini-3-pro-preview"
    }
}

#[cfg(test)]
mod tests {
    #[test]
    fn test_model_mapping() {
        assert_eq!(map_model_name("claude-3-5-sonnet-20241022"), "gemini-3-pro-preview");
        assert_eq!(map_model_name("claude-3-opus-20240229"), "gemini-3-pro-preview");
        assert_eq!(map_model_name("claude-3-haiku-20240307"), "gemini-3-pro-preview");
        assert_eq!(map_model_name("unknown-model"), "gemini-3-pro-preview");
    }
}
```

**Acceptance Criteria:**
- [ ] Model mapping tests pass
- [ ] Handles unknown models gracefully

---

### Phase 2: Request Pipeline (Days 4-6)

#### Day 4: Request Transformation Core

**Task 2.1: Content Extraction** (`src/transform/request.rs`)
```rust
use crate::models::claude::{ContentType, ContentBlock};
use crate::models::gemini::GeminiPart;
use crate::error::Result;

pub fn extract_parts(content: ContentType) -> Result<Vec<GeminiPart>> {
    match content {
        ContentType::Text(text) => {
            Ok(vec![GeminiPart::Text { text }])
        }
        ContentType::Blocks(blocks) => {
            let mut parts = Vec::new();
            for block in blocks {
                match block.block_type.as_str() {
                    "text" => {
                        if let Some(text) = block.text {
                            parts.push(GeminiPart::Text { text });
                        }
                    }
                    _ => {
                        // Log warning for unsupported types
                        eprintln!("Unsupported block type: {}", block.block_type);
                    }
                }
            }
            Ok(parts)
        }
    }
}
```

**Task 2.2: System Prompt Conversion**
```rust
use crate::models::claude::SystemPrompt;
use crate::models::gemini::GeminiSystemInstruction;

pub fn convert_system_prompt(system: Option<SystemPrompt>) -> Option<GeminiSystemInstruction> {
    system.map(|sys| {
        let parts = match sys {
            SystemPrompt::Text(text) => vec![GeminiPart::Text { text }],
            SystemPrompt::Blocks(blocks) => blocks
                .into_iter()
                .filter_map(|b| b.text.map(|text| GeminiPart::Text { text }))
                .collect(),
        };
        GeminiSystemInstruction { parts }
    })
}
```

**Task 2.3: Main Transform Function**
```rust
use crate::models::claude::ClaudeRequest;
use crate::models::gemini::{GeminiRequest, GeminiContent, GenerationConfig};

pub fn transform_request(claude_req: ClaudeRequest) -> Result<GeminiRequest> {
    // 1. Convert messages
    let mut contents = Vec::new();
    for msg in claude_req.messages {
        let role = match msg.role.as_str() {
            "assistant" => "model",
            "user" => "user",
            _ => return Err(ProxyError::TransformationError(
                format!("Invalid role: {}", msg.role)
            )),
        };

        let parts = extract_parts(msg.content)?;

        contents.push(GeminiContent {
            role: role.to_string(),
            parts,
        });
    }

    // 2. Convert system prompt
    let system_instruction = convert_system_prompt(claude_req.system);

    // 3. Build generation config
    let generation_config = Some(GenerationConfig {
        max_output_tokens: claude_req.max_tokens,
        temperature: claude_req.temperature,
        top_p: claude_req.top_p,
        top_k: claude_req.top_k,
        stop_sequences: claude_req.stop_sequences,
    });

    Ok(GeminiRequest {
        contents,
        system_instruction,
        generation_config,
        safety_settings: None,
    })
}
```

**Acceptance Criteria:**
- [ ] Simple text messages transform correctly
- [ ] System prompts convert properly
- [ ] Content blocks filter to text only
- [ ] Role mapping (assistant → model) works
- [ ] Generation config maps all fields
- [ ] Unit tests cover all transformation paths

#### Day 5: Request Validation

**Task 2.4: Input Validation** (`src/transform/validation.rs`)
```rust
use crate::models::claude::ClaudeRequest;
use crate::error::{ProxyError, Result};

pub fn validate_claude_request(req: &ClaudeRequest) -> Result<()> {
    // Check message count
    if req.messages.is_empty() {
        return Err(ProxyError::InvalidClaudeRequest(
            "No messages provided".into()
        ));
    }

    // Validate first message is from user
    if req.messages[0].role != "user" {
        return Err(ProxyError::InvalidClaudeRequest(
            "First message must be from user".into()
        ));
    }

    // Validate role alternation (relaxed - just check no consecutive assistants)
    let mut prev_role: Option<&str> = None;
    for msg in &req.messages {
        if let Some(prev) = prev_role {
            if prev == "assistant" && msg.role == "assistant" {
                return Err(ProxyError::InvalidClaudeRequest(
                    "Cannot have consecutive assistant messages".into()
                ));
            }
        }
        prev_role = Some(&msg.role);
    }

    // Check token limits
    if let Some(max_tokens) = req.max_tokens {
        if max_tokens == 0 || max_tokens > 1_000_000 {
            return Err(ProxyError::InvalidClaudeRequest(
                format!("Invalid max_tokens: {}", max_tokens)
            ));
        }
    }

    // Validate temperature
    if let Some(temp) = req.temperature {
        if !(0.0..=2.0).contains(&temp) {
            return Err(ProxyError::InvalidClaudeRequest(
                format!("Invalid temperature: {}", temp)
            ));
        }
    }

    Ok(())
}
```

**Acceptance Criteria:**
- [ ] Empty messages rejected
- [ ] Invalid role sequences rejected
- [ ] Token limits enforced
- [ ] Temperature bounds checked
- [ ] Valid requests pass validation

#### Day 6: Request Pipeline Integration Tests

**Task 2.5: End-to-End Request Tests** (`tests/request_transform.rs`)
```rust
use claude_code_proxy::models::claude::*;
use claude_code_proxy::transform::*;

#[test]
fn test_simple_request_transformation() {
    let claude_req = ClaudeRequest {
        model: "claude-3-5-sonnet-20241022".to_string(),
        messages: vec![
            ClaudeMessage {
                role: "user".to_string(),
                content: ContentType::Text("Hello".to_string()),
            }
        ],
        system: None,
        max_tokens: Some(100),
        temperature: None,
        stop_sequences: None,
        stream: true,
        top_p: None,
        top_k: None,
    };

    let gemini_req = transform_request(claude_req).unwrap();

    assert_eq!(gemini_req.contents.len(), 1);
    assert_eq!(gemini_req.contents[0].role, "user");
    assert!(gemini_req.system_instruction.is_none());
}

#[test]
fn test_request_with_system_prompt() {
    // Test system prompt conversion
}

#[test]
fn test_request_validation_errors() {
    // Test various validation failures
}
```

**Acceptance Criteria:**
- [ ] All request transformation tests pass
- [ ] Edge cases covered (empty content, long messages, etc.)
- [ ] Validation errors properly tested

---

### Phase 3: Response Pipeline (Days 7-10)

#### Day 7: Streaming JSON Parser

**Task 3.1: Parser State Machine** (`src/streaming/parser.rs`)
```rust
use bytes::{Bytes, BytesMut, Buf};
use crate::models::gemini::GeminiStreamChunk;
use crate::error::Result;

pub struct StreamingJsonParser {
    buffer: BytesMut,
    array_started: bool,
}

impl StreamingJsonParser {
    pub fn new() -> Self {
        Self {
            buffer: BytesMut::with_capacity(8192),
            array_started: false,
        }
    }

    /// Feed new data and extract complete JSON objects
    pub fn feed(&mut self, chunk: &[u8]) -> Result<Vec<GeminiStreamChunk>> {
        self.buffer.extend_from_slice(chunk);
        self.extract_objects()
    }

    fn extract_objects(&mut self) -> Result<Vec<GeminiStreamChunk>> {
        let mut results = Vec::new();

        loop {
            self.skip_noise();

            if self.buffer.is_empty() {
                break;
            }

            // Check for array end
            if self.buffer[0] == b']' {
                self.buffer.advance(1);
                continue;
            }

            // Find complete JSON object
            if let Some(obj_end) = self.find_object_boundary() {
                let obj_bytes = self.buffer.split_to(obj_end);

                match serde_json::from_slice::<GeminiStreamChunk>(&obj_bytes) {
                    Ok(chunk) => results.push(chunk),
                    Err(e) => {
                        eprintln!("Failed to parse chunk: {}", e);
                        eprintln!("Raw: {}", String::from_utf8_lossy(&obj_bytes));
                    }
                }
            } else {
                // Incomplete object, wait for more data
                break;
            }
        }

        Ok(results)
    }

    fn skip_noise(&mut self) {
        while !self.buffer.is_empty() {
            match self.buffer[0] {
                b'[' => {
                    self.array_started = true;
                    self.buffer.advance(1);
                }
                b',' | b' ' | b'\n' | b'\r' | b'\t' => {
                    self.buffer.advance(1);
                }
                _ => break,
            }
        }
    }

    fn find_object_boundary(&self) -> Option<usize> {
        let mut depth = 0;
        let mut in_string = false;
        let mut escaped = false;

        for (i, &byte) in self.buffer.iter().enumerate() {
            if in_string {
                if escaped {
                    escaped = false;
                } else {
                    match byte {
                        b'\\' => escaped = true,
                        b'"' => in_string = false,
                        _ => {}
                    }
                }
            } else {
                match byte {
                    b'"' => in_string = true,
                    b'{' => depth += 1,
                    b'}' => {
                        depth -= 1;
                        if depth == 0 {
                            return Some(i + 1);
                        }
                    }
                    _ => {}
                }
            }
        }

        None
    }
}
```

**Task 3.2: Parser Unit Tests**
```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_complete_object() {
        let mut parser = StreamingJsonParser::new();
        let data = b"[{\"candidates\":[]}]";
        let chunks = parser.feed(data).unwrap();
        assert_eq!(chunks.len(), 1);
    }

    #[test]
    fn test_parse_incomplete_chunks() {
        let mut parser = StreamingJsonParser::new();

        // First chunk is incomplete
        let chunk1 = b"[{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"H";
        let results1 = parser.feed(chunk1).unwrap();
        assert_eq!(results1.len(), 0);

        // Second chunk completes first object
        let chunk2 = b"ello\"}]}}]}";
        let results2 = parser.feed(chunk2).unwrap();
        assert_eq!(results2.len(), 1);
    }

    #[test]
    fn test_multiple_objects() {
        let mut parser = StreamingJsonParser::new();
        let data = b"[{\"candidates\":[]},{\"candidates\":[]}]";
        let chunks = parser.feed(data).unwrap();
        assert_eq!(chunks.len(), 2);
    }

    #[test]
    fn test_escaped_strings() {
        let mut parser = StreamingJsonParser::new();
        let data = b"[{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"He said \\\"hello\\\"\"}]}}]}]";
        let chunks = parser.feed(data).unwrap();
        assert_eq!(chunks.len(), 1);
    }
}
```

**Acceptance Criteria:**
- [ ] Parser handles complete objects
- [ ] Parser buffers incomplete objects
- [ ] Parser handles multiple objects in one chunk
- [ ] Parser handles object split across chunks
- [ ] Escaped strings parsed correctly
- [ ] All parser unit tests pass

#### Day 8: SSE Event Generator

**Task 3.3: Event Generator** (`src/streaming/sse.rs`)
```rust
use crate::models::gemini::GeminiStreamChunk;
use crate::models::claude::*;
use serde::Serialize;

pub struct SSEEventGenerator {
    header_sent: bool,
    input_tokens: u32,
    output_tokens: u32,
    model_name: String,
}

impl SSEEventGenerator {
    pub fn new(model_name: String) -> Self {
        Self {
            header_sent: false,
            input_tokens: 0,
            output_tokens: 0,
            model_name,
        }
    }

    pub fn generate_events(&mut self, chunk: GeminiStreamChunk) -> Vec<String> {
        let mut events = Vec::new();

        // Send header events on first chunk
        if !self.header_sent {
            if let Some(usage) = &chunk.usage_metadata {
                self.input_tokens = usage.prompt_token_count.unwrap_or(0);
            }

            events.push(self.format_message_start());
            events.push(self.format_content_block_start());
            self.header_sent = true;
        }

        // Process candidates
        if let Some(candidate) = chunk.candidates.first() {
            // Extract text deltas
            if let Some(content) = &candidate.content {
                for part in &content.parts {
                    if let GeminiPart::Text { text } = part {
                        if !text.is_empty() {
                            events.push(self.format_content_block_delta(text));
                            self.output_tokens += (text.len() / 4) as u32;
                        }
                    }
                }
            }

            // Handle finish
            if let Some(finish_reason) = &candidate.finish_reason {
                let stop_reason = self.map_finish_reason(finish_reason);

                if let Some(usage) = &chunk.usage_metadata {
                    self.output_tokens = usage.candidates_token_count
                        .unwrap_or(self.output_tokens);
                }

                events.push(self.format_content_block_stop());
                events.push(self.format_message_delta(stop_reason));
                events.push(self.format_message_stop());
            }
        }

        events
    }

    fn format_message_start(&self) -> String {
        let data = serde_json::json!({
            "type": "message_start",
            "message": {
                "id": format!("msg_gemini_{}", uuid::Uuid::new_v4()),
                "type": "message",
                "role": "assistant",
                "model": self.model_name,
                "content": [],
                "stop_reason": null,
                "stop_sequence": null,
                "usage": {
                    "input_tokens": self.input_tokens,
                    "output_tokens": 0
                }
            }
        });
        format!("event: message_start\ndata: {}\n\n", data)
    }

    fn format_content_block_start(&self) -> String {
        let data = serde_json::json!({
            "type": "content_block_start",
            "index": 0,
            "content_block": {
                "type": "text",
                "text": ""
            }
        });
        format!("event: content_block_start\ndata: {}\n\n", data)
    }

    fn format_content_block_delta(&self, text: &str) -> String {
        let data = serde_json::json!({
            "type": "content_block_delta",
            "index": 0,
            "delta": {
                "type": "text_delta",
                "text": text
            }
        });
        format!("event: content_block_delta\ndata: {}\n\n", data)
    }

    fn format_content_block_stop(&self) -> String {
        let data = serde_json::json!({
            "type": "content_block_stop",
            "index": 0
        });
        format!("event: content_block_stop\ndata: {}\n\n", data)
    }

    fn format_message_delta(&self, stop_reason: &str) -> String {
        let data = serde_json::json!({
            "type": "message_delta",
            "delta": {
                "stop_reason": stop_reason,
                "stop_sequence": null
            },
            "usage": {
                "output_tokens": self.output_tokens
            }
        });
        format!("event: message_delta\ndata: {}\n\n", data)
    }

    fn format_message_stop(&self) -> String {
        format!("event: message_stop\ndata: {{\"type\":\"message_stop\"}}\n\n")
    }

    fn map_finish_reason(&self, gemini_reason: &str) -> &'static str {
        match gemini_reason {
            "STOP" => "end_turn",
            "MAX_TOKENS" => "max_tokens",
            "SAFETY" => "stop_sequence",
            "RECITATION" => "stop_sequence",
            _ => "end_turn",
        }
    }
}
```

**Acceptance Criteria:**
- [ ] Generates correct message_start event
- [ ] Generates correct content_block_delta events
- [ ] Generates correct message_stop event
- [ ] Token counting works (approximate)
- [ ] Finish reason mapping correct

#### Day 9-10: Response Pipeline Integration

**Task 3.4: Combined Parser + Generator Tests**
```rust
#[test]
fn test_complete_streaming_pipeline() {
    let mut parser = StreamingJsonParser::new();
    let mut generator = SSEEventGenerator::new("gemini-3-pro-preview".to_string());

    // Simulate streaming chunks
    let chunk1 = b"[{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"Hello\"}]}}],\"usageMetadata\":{\"promptTokenCount\":10}}";
    let chunk2 = b",{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\" world\"}]}}]}";
    let chunk3 = b",{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"!\"}]},\"finishReason\":\"STOP\"}],\"usageMetadata\":{\"candidatesTokenCount\":5}}]";

    let mut all_events = Vec::new();

    for chunk in [chunk1, chunk2, chunk3] {
        let parsed = parser.feed(chunk).unwrap();
        for gemini_chunk in parsed {
            let events = generator.generate_events(gemini_chunk);
            all_events.extend(events);
        }
    }

    // Verify event sequence
    assert!(all_events.iter().any(|e| e.contains("message_start")));
    assert!(all_events.iter().any(|e| e.contains("content_block_start")));
    assert!(all_events.iter().any(|e| e.contains("content_block_delta")));
    assert!(all_events.iter().any(|e| e.contains("content_block_stop")));
    assert!(all_events.iter().any(|e| e.contains("message_stop")));
}
```

**Acceptance Criteria:**
- [ ] Full pipeline test passes
- [ ] SSE format is valid
- [ ] Event ordering is correct
- [ ] Token counts are reasonable

---

### Phase 4: Pingora Integration (Days 11-13)

#### Day 11: Basic Proxy Structure

**Task 4.1: Proxy Context** (`src/proxy.rs`)
```rust
use bytes::{Bytes, BytesMut, BufMut};
use crate::streaming::{StreamingJsonParser, SSEEventGenerator};

pub struct RequestContext {
    // Request transformation
    pub transformed_body: Option<Bytes>,
    pub target_model: String,

    // Response streaming
    pub parser: StreamingJsonParser,
    pub event_generator: SSEEventGenerator,

    // Output buffering
    pub outgoing_events: BytesMut,
}

impl RequestContext {
    pub fn new() -> Self {
        Self {
            transformed_body: None,
            target_model: "gemini-3-pro-preview".to_string(),
            parser: StreamingJsonParser::new(),
            event_generator: SSEEventGenerator::new("gemini-3-pro-preview".to_string()),
            outgoing_events: BytesMut::new(),
        }
    }
}
```

**Task 4.2: Proxy Implementation** (`src/proxy.rs`)
```rust
use async_trait::async_trait;
use pingora::prelude::*;
use std::sync::Arc;
use crate::config::ProxyConfig;
use crate::transform::*;

pub struct ClaudeToGeminiProxy {
    config: Arc<ProxyConfig>,
}

impl ClaudeToGeminiProxy {
    pub fn new(config: ProxyConfig) -> Self {
        Self {
            config: Arc::new(config),
        }
    }
}

#[async_trait]
impl ProxyHttp for ClaudeToGeminiProxy {
    type CTX = RequestContext;

    fn new_ctx(&self) -> Self::CTX {
        RequestContext::new()
    }

    async fn upstream_peer(
        &self,
        _session: &mut Session,
        _ctx: &mut Self::CTX,
    ) -> Result<Box<HttpPeer>> {
        let peer = Box::new(HttpPeer::new(
            (&self.config.gemini.endpoint as &str, 443),
            true,  // TLS
            self.config.gemini.endpoint.clone(),  // SNI
        ));

        Ok(peer)
    }

    // Continue with other trait methods...
}
```

#### Day 12: Request/Response Filters

**Task 4.3: Request Filter Implementation**
```rust
async fn request_filter(
    &self,
    session: &mut Session,
    ctx: &mut Self::CTX,
) -> Result<bool> {
    // Read request body
    let body_bytes = match session.read_request_body().await? {
        Some(b) => b,
        None => {
            return Err(Error::explain(
                ErrorType::InvalidHTTPHeader,
                "Empty request body"
            ));
        }
    };

    // Parse Claude request
    let claude_req: ClaudeRequest = serde_json::from_slice(&body_bytes)
        .map_err(|e| Error::explain(
            ErrorType::InvalidHTTPHeader,
            format!("Invalid Claude request: {}", e)
        ))?;

    // Validate
    validate_claude_request(&claude_req)
        .map_err(|e| Error::explain(ErrorType::InvalidHTTPHeader, e.to_string()))?;

    // Map model
    ctx.target_model = map_model_name(&claude_req.model).to_string();
    ctx.event_generator = SSEEventGenerator::new(ctx.target_model.clone());

    // Transform
    let gemini_req = transform_request(claude_req)
        .map_err(|e| Error::explain(ErrorType::InternalError, e.to_string()))?;

    // Serialize
    let transformed = serde_json::to_vec(&gemini_req)
        .map_err(|e| Error::explain(ErrorType::InternalError, e.to_string()))?;

    ctx.transformed_body = Some(Bytes::from(transformed));

    Ok(false)
}
```

**Task 4.4: Upstream Request Filter**
```rust
async fn upstream_request_filter(
    &self,
    session: &mut Session,
    ctx: &mut Self::CTX,
) -> Result<()> {
    let header = session.req_header_mut();

    // Rewrite URL
    let new_uri = format!(
        "/v1beta/models/{}:streamGenerateContent?key={}",
        ctx.target_model,
        self.config.gemini.api_key
    );
    header.set_uri(new_uri.parse().unwrap());

    // Set headers
    header.insert_header("Host", &self.config.gemini.endpoint)?;
    header.insert_header("Content-Type", "application/json")?;
    header.remove_header("x-api-key");

    if let Some(body) = &ctx.transformed_body {
        header.insert_header("Content-Length", body.len().to_string())?;
    }

    Ok(())
}

async fn request_body_filter(
    &self,
    _session: &mut Session,
    body: &mut Option<Bytes>,
    _end: bool,
    ctx: &mut Self::CTX,
) -> Result<()> {
    *body = ctx.transformed_body.take();
    Ok(())
}
```

**Task 4.5: Response Filters**
```rust
async fn response_filter(
    &self,
    session: &mut Session,
    _upstream_response: &mut ResponseHeader,
    _ctx: &mut Self::CTX,
) -> Result<()> {
    let header = session.response_written_mut().unwrap();
    header.insert_header("Content-Type", "text/event-stream")?;
    header.insert_header("Cache-Control", "no-cache")?;
    header.insert_header("Connection", "keep-alive")?;
    header.remove_header("Content-Length");

    Ok(())
}

async fn response_body_filter(
    &self,
    _session: &mut Session,
    body: &mut Option<Bytes>,
    end_of_stream: bool,
    ctx: &mut Self::CTX,
) -> Result<Option<Duration>> {
    // Feed new data to parser
    if let Some(chunk) = body.take() {
        let parsed_chunks = ctx.parser.feed(&chunk)
            .map_err(|e| Error::explain(ErrorType::InternalError, e.to_string()))?;

        // Generate SSE events
        for gemini_chunk in parsed_chunks {
            let events = ctx.event_generator.generate_events(gemini_chunk);
            for event in events {
                ctx.outgoing_events.put(event.as_bytes());
            }
        }
    }

    // Output accumulated events
    if !ctx.outgoing_events.is_empty() {
        *body = Some(ctx.outgoing_events.split().freeze());
    }

    // Handle stream end
    if end_of_stream && body.is_none() {
        if !ctx.event_generator.header_sent {
            eprintln!("Warning: Stream ended without data");
        }
    }

    Ok(None)
}
```

#### Day 13: Main Server Setup

**Task 4.6: Main Entry Point** (`src/main.rs`)
```rust
use claude_code_proxy::{config::ProxyConfig, proxy::ClaudeToGeminiProxy};
use pingora::prelude::*;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    env_logger::init();

    // Load config
    let config = ProxyConfig::from_env()?;

    // Create server
    let mut server = Server::new(None)?;
    server.bootstrap();

    // Create proxy
    let proxy = ClaudeToGeminiProxy::new(config.clone());

    // Create service
    let mut service = http_proxy_service(&server.configuration, proxy);
    service.add_tcp(&config.server.listen_addr);

    server.add_service(service);
    server.run_forever();
}
```

**Task 4.7: Library Exports** (`src/lib.rs`)
```rust
pub mod config;
pub mod error;
pub mod models;
pub mod proxy;
pub mod streaming;
pub mod transform;

pub use config::ProxyConfig;
pub use proxy::ClaudeToGeminiProxy;
```

**Acceptance Criteria:**
- [ ] Proxy compiles without errors
- [ ] Server starts and listens on configured port
- [ ] Can handle basic HTTP requests

---

### Phase 5: Testing & Refinement (Days 14-16)

#### Day 14: Integration Tests

**Task 5.1: Mock Gemini Server** (`tests/mock_server.rs`)
```rust
use warp::Filter;

pub async fn start_mock_gemini() -> u16 {
    let route = warp::post()
        .and(warp::path!("v1beta" / "models" / String / "streamGenerateContent"))
        .and(warp::body::json())
        .map(|_model: String, _body: serde_json::Value| {
            // Return mock streaming response
            let response = r#"[
                {"candidates":[{"content":{"parts":[{"text":"Hello"}]}}],"usageMetadata":{"promptTokenCount":10}},
                {"candidates":[{"content":{"parts":[{"text":" world"}]}}]},
                {"candidates":[{"content":{"parts":[{"text":"!"}]},"finishReason":"STOP"}],"usageMetadata":{"candidatesTokenCount":3}}
            ]"#;

            warp::reply::with_header(
                response,
                "content-type",
                "application/json"
            )
        });

    let (addr, server) = warp::serve(route)
        .bind_ephemeral(([127, 0, 0, 1], 0));

    tokio::spawn(server);
    addr.port()
}
```

**Task 5.2: End-to-End Test** (`tests/integration.rs`)
```rust
#[tokio::test]
async fn test_full_proxy_flow() {
    // Start mock Gemini
    let gemini_port = start_mock_gemini().await;

    // Start proxy
    let config = ProxyConfig {
        server: ServerConfig {
            listen_addr: "127.0.0.1:0".to_string(),
            workers: 1,
        },
        gemini: GeminiConfig {
            api_key: "test-key".to_string(),
            endpoint: format!("localhost:{}", gemini_port),
        },
    };

    let proxy_port = start_proxy(config).await;

    // Send Claude request
    let client = reqwest::Client::new();
    let response = client
        .post(format!("http://localhost:{}/v1/messages", proxy_port))
        .header("x-api-key", "test-key")
        .json(&serde_json::json!({
            "model": "claude-3-5-sonnet",
            "messages": [{"role": "user", "content": "Hello"}],
            "stream": true,
            "max_tokens": 10
        }))
        .send()
        .await
        .unwrap();

    // Verify response
    assert_eq!(response.status(), 200);
    assert_eq!(
        response.headers()["content-type"],
        "text/event-stream"
    );

    // Parse SSE events
    let body = response.text().await.unwrap();
    assert!(body.contains("event: message_start"));
    assert!(body.contains("event: content_block_delta"));
    assert!(body.contains("event: message_stop"));
}
```

#### Day 15: Error Handling Tests

**Task 5.3: Error Scenarios**
```rust
#[tokio::test]
async fn test_invalid_claude_request() {
    // Test empty messages
    // Test invalid role
    // Test missing required fields
}

#[tokio::test]
async fn test_gemini_error_response() {
    // Test 400 error
    // Test 401 authentication error
    // Test 429 rate limit
}

#[tokio::test]
async fn test_malformed_gemini_stream() {
    // Test incomplete JSON
    // Test invalid JSON
    // Test unexpected stream termination
}
```

#### Day 16: Performance Testing

**Task 5.4: Benchmark Suite** (`benches/streaming_parser.rs`)
```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use claude_code_proxy::streaming::StreamingJsonParser;

fn benchmark_parser(c: &mut Criterion) {
    let data = include_bytes!("../tests/fixtures/gemini_large_stream.json");

    c.bench_function("parse_gemini_stream", |b| {
        b.iter(|| {
            let mut parser = StreamingJsonParser::new();
            parser.feed(black_box(data)).unwrap()
        });
    });
}

criterion_group!(benches, benchmark_parser);
criterion_main!(benches);
```

**Task 5.5: Load Testing**
```bash
# Create load test script
cat > load_test.sh <<'EOF'
#!/bin/bash
echo "POST http://localhost:8080/v1/messages" | \
  vegeta attack \
    -duration=30s \
    -rate=50/s \
    -body=tests/fixtures/claude_request_simple.json \
    -header="x-api-key: test" \
    -header="Content-Type: application/json" \
  | vegeta report -type=text
EOF
chmod +x load_test.sh
```

**Acceptance Criteria:**
- [ ] All integration tests pass
- [ ] Error scenarios handled gracefully
- [ ] Benchmark shows acceptable performance (< 1ms parsing overhead)
- [ ] Load test shows > 100 req/s throughput

---

### Phase 6: Documentation & Polish (Days 17-18)

#### Day 17: Documentation

**Task 6.1: README** (`README.md`)
```markdown
# Claude Code Proxy

High-performance protocol translation proxy that allows Claude Code CLI to use Google Gemini models.

## Features

- Transparent protocol conversion (Claude Messages API ↔ Gemini GenerateContent API)
- Real-time streaming with SSE support
- Zero-copy buffer management for minimal latency
- Production-ready error handling

## Quick Start

### Installation

\`\`\`bash
cargo build --release
\`\`\`

### Configuration

\`\`\`bash
export GEMINI_API_KEY="your-api-key"
export PROXY_LISTEN_ADDR="127.0.0.1:8080"
\`\`\`

### Running

\`\`\`bash
./target/release/claude-code-proxy
\`\`\`

### Using with Claude Code

\`\`\`bash
export ANTHROPIC_API_URL="http://localhost:8080"
export ANTHROPIC_API_KEY="placeholder"
claude-code
\`\`\`

## Architecture

[Include architecture diagram]

## Testing

\`\`\`bash
cargo test
cargo bench
\`\`\`

## License

MIT
```

**Task 6.2: API Documentation**
```bash
# Generate docs
cargo doc --no-deps --open
```

Add module-level documentation to all public modules.

**Task 6.3: Examples** (`examples/simple.rs`)
```rust
use claude_code_proxy::{config::ProxyConfig, proxy::ClaudeToGeminiProxy};

fn main() {
    // Example of programmatic usage
}
```

#### Day 18: Final Polish

**Task 6.4: Code Quality**
```bash
# Format code
cargo fmt

# Lint
cargo clippy -- -D warnings

# Check for common issues
cargo deny check
```

**Task 6.5: CI/CD Setup** (`.github/workflows/ci.yml`)
```yaml
name: CI

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      - run: cargo test --all-features
      - run: cargo clippy -- -D warnings
      - run: cargo fmt -- --check
```

**Task 6.6: Release Checklist**
- [ ] All tests passing
- [ ] Documentation complete
- [ ] Examples working
- [ ] CHANGELOG.md updated
- [ ] Version bumped in Cargo.toml
- [ ] CI passing

**Acceptance Criteria:**
- [ ] README is comprehensive
- [ ] All public APIs documented
- [ ] Examples run successfully
- [ ] CI/CD pipeline working
- [ ] Code passes all quality checks

---

## 4. Testing Matrix

### Unit Tests
| Component              | Tests | Status |
|------------------------|-------|--------|
| Model mapping          | 4     | ⬜      |
| Request transformation | 8     | ⬜      |
| Request validation     | 6     | ⬜      |
| JSON parser            | 10    | ⬜      |
| SSE generator          | 8     | ⬜      |
| Error types            | 4     | ⬜      |

### Integration Tests
| Scenario           | Description         | Status |
|--------------------|---------------------|--------|
| Simple request     | Basic text message  | ⬜      |
| With system prompt | System instructions | ⬜      |
| Content blocks     | Multi-block content | ⬜      |
| Streaming          | Full SSE stream     | ⬜      |
| Error handling     | API errors          | ⬜      |
| Large prompts      | >10KB requests      | ⬜      |

### Performance Tests
| Metric             | Target      | Status |
|--------------------|-------------|--------|
| Parser latency     | < 1ms       | ⬜      |
| Throughput         | > 100 req/s | ⬜      |
| Memory per request | < 1MB       | ⬜      |
| End-to-end latency | < 10ms      | ⬜      |

---

## 5. Risk Management

### High-Risk Items

**Risk 1: Pingora API Changes**
- **Mitigation**: Pin to specific version, test thoroughly
- **Contingency**: Consider alternative frameworks (hyper, axum)

**Risk 2: Gemini API Changes**
- **Mitigation**: Version lock API endpoint, monitor Google docs
- **Contingency**: Implement version negotiation

**Risk 3: Incomplete Streaming Data**
- **Mitigation**: Robust parser state machine, extensive testing
- **Contingency**: Add timeout and retry logic

### Medium-Risk Items

**Risk 4: Performance Bottlenecks**
- **Mitigation**: Early benchmarking, profiling
- **Contingency**: Optimize critical paths, consider caching

**Risk 5: Edge Case Handling**
- **Mitigation**: Comprehensive test suite, fuzzing
- **Contingency**: Graceful degradation, detailed logging

---

## 6. Success Metrics

### Phase 1 Success
- [ ] All data models compile and serialize correctly
- [ ] Configuration system working
- [ ] Basic transformations implemented

### Phase 2 Success
- [ ] Full request transformation working
- [ ] Validation comprehensive
- [ ] All unit tests passing

### Phase 3 Success
- [ ] Streaming parser handles all edge cases
- [ ] SSE generation matches Claude format
- [ ] Integration tests passing

### Phase 4 Success
- [ ] Pingora proxy fully integrated
- [ ] End-to-end flow working
- [ ] Can successfully proxy Claude Code requests

### Phase 5 Success
- [ ] All tests passing (unit + integration)
- [ ] Performance meets targets
- [ ] Error handling robust

### Phase 6 Success
- [ ] Documentation complete
- [ ] Examples working
- [ ] Ready for release

---

## 7. Deployment Checklist

### Pre-Deployment
- [ ] All tests passing
- [ ] Performance benchmarks met
- [ ] Security review complete
- [ ] Documentation reviewed

### Deployment Steps
1. Build release binary: `cargo build --release`
2. Set environment variables
3. Start proxy server
4. Configure Claude Code
5. Verify connectivity
6. Monitor logs

### Post-Deployment
- [ ] Monitor error rates
- [ ] Check latency metrics
- [ ] Verify token counting accuracy
- [ ] User acceptance testing

---

## 8. Maintenance Plan

### Weekly
- Review error logs
- Monitor performance metrics
- Check for API changes

### Monthly
- Update dependencies
- Review security advisories
- Performance optimization

### Quarterly
- Major version updates
- Feature additions
- Architecture review

---

## 9. Future Roadmap (Post Phase 1)

### Phase 2: Multi-Model Support
- Add OpenAI backend
- Add DeepSeek backend
- Implement model routing

### Phase 3: Advanced Features
- Response caching
- Function calling support
- Image/multimodal support

### Phase 4: Production Hardening
- Metrics and monitoring
- Distributed tracing
- Rate limiting
- Circuit breakers

### Phase 5: Optimization
- Connection pooling
- Request batching
- Advanced caching strategies

---

## 10. Notes & Decisions

### Key Decisions
1. **Pingora over Axum**: Better suited for high-performance proxy use cases
2. **Full buffer vs streaming**: Buffer requests (small), stream responses (large)
3. **Token estimation**: Use approximation (4 chars/token) rather than full tokenization

### Open Questions
- [ ] How to handle Gemini "thinking" tokens?
- [ ] Support for non-streaming requests?
- [ ] Vertex AI vs. Gemini API endpoint?

### Lessons Learned
(To be filled during implementation)

---

## Appendix A: Dependencies

```toml
[dependencies]
anyhow = "1.0.100"
async-trait = "0.1"
bytes = "1.6"
pingora = { version = "0.6.0", features = ["cache", "lb", "rustls"] }
serde = { version = "1.0.228", features = ["derive"] }
serde_json = "1.0.145"
thiserror = "2.0.17"
tokio = { version = "1.48.0", features = ["rt-multi-thread", "macros"] }
uuid = { version = "1.11", features = ["v4", "serde"] }

[dev-dependencies]
criterion = "0.5"
reqwest = "0.12"
warp = "0.3"

[build-dependencies]
# None initially
```

## Appendix B: File Checklist

- [ ] `src/lib.rs`
- [ ] `src/main.rs`
- [ ] `src/error.rs`
- [ ] `src/config.rs`
- [ ] `src/proxy.rs`
- [ ] `src/models/mod.rs`
- [ ] `src/models/claude.rs`
- [ ] `src/models/gemini.rs`
- [ ] `src/transform/mod.rs`
- [ ] `src/transform/request.rs`
- [ ] `src/transform/validation.rs`
- [ ] `src/streaming/mod.rs`
- [ ] `src/streaming/parser.rs`
- [ ] `src/streaming/sse.rs`
- [ ] `tests/integration.rs`
- [ ] `tests/request_transform.rs`
- [ ] `tests/mock_server.rs`
- [ ] `benches/streaming_parser.rs`
- [ ] `examples/simple.rs`
- [ ] `README.md`
- [ ] `CHANGELOG.md`
- [ ] `.github/workflows/ci.yml`

---

**End of Implementation Plan**

*Last Updated: 2025-11-18*
