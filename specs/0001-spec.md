
# **基于 Rust 与 Cloudflare Pingora 构建高性能 Claude-to-Gemini 协议转换网关的深度研究报告**

## **1. 执行摘要 (Executive Summary)**

随着生成式人工智能（GenAI）生态系统的迅速扩张，大语言模型（LLM）的接口碎片化问题日益凸显。尽管 Anthropic 的 Claude 系列模型在推理能力上表现卓越，其配套的开发者工具——特别是新发布的 "Claude Code" 命令行代理——通常与 Anthropic 的 proprietary API 深度绑定。然而，从成本效益、上下文窗口大小以及推理速度的角度考量，Google 的 Gemini 1.5 Pro 和 Flash 模型往往提供了极具竞争力的替代方案。本报告旨在详尽阐述如何利用 Rust 语言结合 Cloudflare 开源的 pingora 框架，构建一个企业级、高并发的 API 代理（Proxy）。该系统的核心目标是实现实时的协议转换（Protocol Translation），将 Claude 风格的请求透明地转换为 Gemini 风格的负载，并处理复杂的流式响应（Streaming Response）映射，从而允许用户在 Claude Code 环境中直接使用 Google Gemini 模型。

本研究报告将深入剖析 Anthropic Messages API 与 Google Vertex AI/Generative Language API 之间的协议阻抗失配（Impedance Mismatch），特别是 Server-Sent Events (SSE) 与分块 JSON 数组（Chunked JSON Array）之间的传输差异。我们将提供一个基于 Pingora 的完整系统架构设计，涵盖从底层的字节流处理到上层的语义映射，并探讨如何通过 Rust 的所有权机制与零拷贝（Zero-copy）技术来最小化代理层的延迟损耗。

---

## **2. 绪论与技术背景 (Introduction & Technical Context)**

在当前的 LLM 应用开发中，工具链的锁定效应是一个显著的挑战。开发者往往受限于特定模型提供商的 SDK 或 CLI 工具。例如，"Claude Code" 作为一个强大的辅助编程代理，预设了与 Claude API 的通信模式。然而，多元化的模型策略要求基础设施具备灵活性，即 "Bring Your Own Model" (BYOM)。

### **2.1 协议转换的必要性与挑战**

构建 API 代理并非简单的数据转发，而是涉及深度的语义重构。Claude API 和 Gemini API 在设计哲学上存在根本性差异：

1. **状态管理**：Claude 严格强制执行 user 与 assistant 的交替对话结构，而 Gemini 在某些版本中对角色序列更为宽容，但对 system 指令的处理位置不同。
2. **流式传输协议**：这是最大的技术鸿沟。Claude 使用标准的 SSE (text/event-stream)，以行（Line-based）为单位发送事件；而 Gemini 的 streamGenerateContent 接口返回的是一个持续增长的 JSON 对象数组，通过 HTTP 分块传输（Chunked Transfer Encoding）发送 1。
3. **鉴权机制**：Claude 使用 x-api-key，而 Gemini 使用 x-goog-api-key 或 URL 参数。

### **2.2 为何选择 Rust 与 Pingora**

在处理高吞吐量的流式数据转换时，传统的基于 Python (如 FastAPI) 或 Node.js 的代理可能会引入不可忽视的垃圾回收（GC）暂停和内存开销。Cloudflare Pingora 是一个专为高负载网络流量设计的 Rust 异步框架，它提供了类似 Nginx 的反向代理能力，但允许开发者通过 Rust 代码在请求生命周期的特定 "过滤器"（Filters）阶段注入自定义逻辑 3。

* **内存安全与性能**：Rust 的仿射类型系统（Affine Type System）确保了在处理请求体（Body）和响应流时不会发生数据竞争，且能有效控制内存占用。
* **可编程性**：Pingora 暴露了 ProxyHttp trait，允许精细控制 request\_filter（请求头处理）、request\_body\_filter（请求体处理）和 response\_body\_filter（响应流处理），这正是协议转换所需的关键钩子 5。

---

## **3. 协议深度剖析与映射策略 (Protocol Deep Dive)**

在编写任何 Rust 代码之前，必须建立源协议（Claude）与目标协议（Gemini）之间的精确映射关系。

### **3.1 请求结构对比分析**

客户端（Claude Code）发送的请求通常遵循 Claude Messages API 规范。我们需要将其解构并重组为 Gemini 的 GenerateContent 结构。

**表 3.1: 请求字段映射对照表**

| 功能域       | Claude API 字段 (POST /v1/messages)   | Gemini API 字段 (streamGenerateContent) | 转换逻辑与处理策略                                                                                                         |
|:-----------|:--------------------------------------|:----------------------------------------|:---------------------------------------------------------------------------------------------------------------------|
| **鉴权**     | Header: x-api-key                     | Header: x-goog-api-key (或 Query Param) | 代理需拦截 Claude Key，替换为用户提供的 Gemini Token。由于用户直接提供 Gemini Token，可将其视为不透明字符串透传 6。            |
| **模型指定** | Body: model (e.g., claude-3-5-sonnet) | URL Path: models/{model}                | 需建立映射表。例如 claude-3-5-sonnet \-\> gemini-1.5-pro。Claude Code 可能会硬编码某些模型名称，代理需做模糊匹配或默认回退 1。 |
| **系统提示** | Body: system (顶级字段)               | Body: systemInstruction                 | Claude 将 System Prompt 作为顶级字符串或对象；Gemini 将其封装在 systemInstruction 对象中，且需包含 parts 数组 9。             |
| **对话历史** | Body: messages (role, content)        | Body: contents (role, parts)            | 核心转换区。Claude 的 content 可以是字符串或块数组；Gemini 统一使用 parts 数组。Role 需映射：assistant \-\> model 8。           |
| **生成控制** | Body: max\_tokens                     | Body: generationConfig.maxOutputTokens  | 直接整数映射。                                                                                                              |
| **停止序列** | Body: stop\_sequences                 | Body: generationConfig.stopSequences    | 直接字符串数组映射。                                                                                                        |
| **流式开关** | Body: stream (boolean)                | API 方法选择                            | 若 stream=true，调用 streamGenerateContent；否则调用 generateContent 1。                                                      |

#### **3.1.1 复杂字段的深入解析：system 与 systemInstruction**

Claude API 允许在顶层直接定义 system 参数，这在构建 Agent 时常用于设定角色设定（Persona）。Gemini API 虽然支持类似功能，但其 JSON 结构更为嵌套。

* **Claude 源数据示例**:
  JSON
  {
    "system": "你是专业的 Rust 工程师。",
    "messages": \[...\]
  }

* **Gemini 目标数据示例** 10:
  JSON
  {
    "systemInstruction": {
      "parts":
    },
    "contents": \[...\]
  }

代理层必须在反序列化 Claude 请求后，提取 system 字段，并将其包装构造为 Gemini 的 Content 对象结构。如果 Claude 请求中没有 system 字段，则在构造 Gemini 请求时应省略 systemInstruction 以避免验证错误。

### **3.2 响应流式传输架构对比 (Streaming Response Architecture)**

这是系统设计中最复杂的部分。Claude Code 作为一个终端应用，极其依赖 SSE 事件来通过打字机效果展示代码。它期望接收到特定的事件序列。

#### **3.2.1 Claude 的 SSE 事件流**

Claude 返回的是符合 text/event-stream 标准的流。每个数据块以 data: 开头，以双换行符结束。

关键事件类型 2:

1. message\_start: 包含 usage 信息（输入 token 消耗）。
2. content\_block\_start: 标记文本块的开始。
3. content\_block\_delta: **核心事件**。包含生成的文本片段 (delta.text)。
4. content\_block\_stop: 块结束。
5. message\_delta: 包含停止原因 (stop\_reason) 和最终消耗 (usage)。
6. message\_stop: 流结束。

#### **3.2.2 Gemini 的分块 JSON 流**

Gemini 的 streamGenerateContent 并不使用标准的 SSE 格式。它返回的是一个 HTTP 分块传输的响应体，但在逻辑上，这些块拼接起来是一个巨大的 JSON 数组。

* **Gemini 响应流示例** 1:
  JSON
  } } \] },
    ,
    { "candidates": \[ { "content": { "parts": \[ { "text": " is" } \] } } \] }
    ,
    { "candidates": \[ { "content": { "parts": \[ { "text": " fast." } \] } } \] }
  \]

注意其中的逗号 , 和方括号 \`\`。网络传输时，TCP 包的边界可能切断任何字符。例如，一个 TCP 包可能只包含 content": { "pa，代理必须缓存这些字节，直到收到完整的 JSON 对象后才能进行解析和转换。

---

## **4. 系统架构设计 (System Architecture)**

基于 Pingora 的架构采用 "Sidecar" 模式或独立网关模式。由于无需维护用户状态（Stateless），主要内存消耗在于请求/响应的缓冲区。

### **4.1 总体架构图 (逻辑视图)**

Code snippet

graph LR
    Client\[Claude Code CLI\] \-- HTTP/1.1 POST /v1/messages (SSE) \--\> Pingora
    subgraph Pingora Proxy Layer
        ReqFilter \-- 1. Buffer Body & Transform \--\> UpstreamReq
        UpstreamReq \-- 2. Inject Token & Rewrite URL \--\> GoogleAPI
        RespFilter \-- 4. Buffer Chunks & Parse JSON \--\> Translator
        Translator \-- 5. Emit SSE Events \--\> Client
    end
    Pingora \-- HTTP/2 POST streamGenerateContent \--\> GoogleAPI\[Google Vertex/Gemini API\]
    GoogleAPI \-- Chunked JSON Stream \--\> Pingora

### **4.2 核心组件设计**

1. **Context (CTX)**: Pingora 允许在请求的生命周期内传递上下文。我们需要定义一个 ProxyContext 结构体，用于存储：
   * response\_buffer: 一个 BytesMut，用于在响应流处理阶段累积来自 Gemini 的不完整字节块。
   * header\_sent: 布尔值，标记是否已经向 Claude 客户端发送了 message\_start 事件。
   * target\_model: 解析出的目标 Gemini 模型名称。
2. **Request Buffer Policy**: 虽然流式请求体通常不建议完全缓冲，但 Claude 的请求体主要是 Prompt 文本，通常只有几 KB 到几 MB。为了简化转换逻辑（需要解析 JSON 才能映射），我们在 request\_filter 阶段读取整个请求体是可行的，也是性能损耗可控的。
3. Streaming Parser State Machine: 在 response\_body\_filter 中，我们需要实现一个轻量级的状态机来解析 Gemini 的 JSON 数组流。不能简单地使用 serde\_json::from\_slice，因为输入数据可能包含前导的 \`
   name \= "claude-gemini-proxy"
   version \= "0.1.0"
   edition \= "2021"

\[dependencies\]
pingora \= { version \= "0.3", features \= \["lb", "openssl"\] }
serde \= { version \= "1.0", features \= \["derive"\] }
serde\_json \= "1.0"
tokio \= { version \= "1", features \= \["full"\] }
async-trait \= "0.1"
bytes \= "1.6"
url \= "2.5"
log \= "0.4"
env\_logger \= "0.10"
http \= "1.1"

\#\#\# 5.2 数据模型定义 (Struct Definitions)

为了利用 Rust 的类型安全，我们必须严格定义 Claude 和 Gemini 的数据结构。

\`\`\`rust
use serde::{Deserialize, Serialize};

// \--- Claude 请求模型 \---
\#
struct ClaudeRequest {
    model: String,
    messages: Vec\<ClaudeMessage\>,
    system: Option\<String\>, // Claude 的 system 是顶层字段
    max\_tokens: Option\<u32\>,
    stream: Option\<bool\>,
}

\#
struct ClaudeMessage {
    role: String,
    content: ContentType, // 可能是字符串，也可能是 ContentBlock 数组
}

\#
\#\[serde(untagged)\] // 处理多态类型
enum ContentType {
    Text(String),
    Blocks(Vec\<ContentBlock\>),
}

\#
struct ContentBlock {
    \#\[serde(rename \= "type")\]
    block\_type: String,
    text: Option\<String\>,
}

// \--- Gemini 请求模型 (目标结构) \---
\#
struct GeminiRequest {
    contents: Vec\<GeminiContent\>,
    \#\[serde(skip\_serializing\_if \= "Option::is\_none")\]
    system\_instruction: Option\<GeminiSystemInstruction\>,
    \#\[serde(skip\_serializing\_if \= "Option::is\_none")\]
    generation\_config: Option\<GeminiGenConfig\>,
}

\#
struct GeminiContent {
    role: String,
    parts: Vec\<GeminiPart\>,
}

\#
struct GeminiSystemInstruction {
    parts: Vec\<GeminiPart\>,
}

\#
struct GeminiPart {
    text: String,
}

\#
struct GeminiGenConfig {
    maxOutputTokens: Option\<u32\>,
}

// \--- Gemini 响应模型 \---
\#
struct GeminiResponseChunk {
    candidates: Option\<Vec\<GeminiCandidate\>\>,
    usageMetadata: Option\<GeminiUsage\>, // 仅在流的最后一部分出现
}

\#
struct GeminiCandidate {
    content: Option\<GeminiContent\>,
    finishReason: Option\<String\>,
}

\#
struct GeminiUsage {
    promptTokenCount: Option\<i32\>,
    candidatesTokenCount: Option\<i32\>,
    totalTokenCount: Option\<i32\>,
}

### **5.3 代理逻辑实现 (Pingora ProxyHttp)**

我们将实现 ProxyHttp trait。核心逻辑分布在 upstream\_peer（连接选择）、request\_filter（请求重写）和 response\_body\_filter（响应流转换）。

#### **5.3.1 上下文与初始化**

Rust

use async\_trait::async\_trait;
use bytes::{BufMut, Bytes, BytesMut};
use pingora::prelude::\*;
use std::sync::Arc;

pub struct ClaudeToGeminiProxy {
    pub gemini\_token: String, // 用户传入的 Token
}

pub struct ProxyContext {
    pub response\_buffer: BytesMut, // 用于拼接不完整的 JSON 块
    pub header\_sent: bool,         // 标记是否已发送 SSE 头事件
    pub target\_model: String,      // 解析出的 Gemini 模型名
}

\#\[async\_trait\]
impl ProxyHttp for ClaudeToGeminiProxy {
    type CTX \= ProxyContext;

    fn new\_ctx(&self) \-\> Self::CTX {
        ProxyContext {
            response\_buffer: BytesMut::new(),
            header\_sent: false,
            target\_model: "gemini-1.5-flash".to\_string(), // 默认回退模型
        }
    }

    // 1. 选择上游 (Google API)
    // 必须正确处理 SNI (Server Name Indication)，否则 Google GFE 会拒绝连接 (403/404)
    async fn upstream\_peer(
        &self,
        \_session: &mut Session,
        \_ctx: &mut Self::CTX,
    ) \-\> Result\<Box\<HttpPeer\>\> {
        // 在生产环境中，应使用 DNS 解析器。此处为示例，假设已解析或使用域名连接。
        // Google API 域名: generativelanguage.googleapis.com
        let addr \= ("generativelanguage.googleapis.com", 443);

        // 构建 TLS Peer
        // 参数 3 (SNI) 必须与 Host 头一致
        let mut peer \= Box::new(HttpPeer::new(addr, true, "generativelanguage.googleapis.com".to\_string()));
        peer.options.set\_http\_version(2, 0); // Google 支持 HTTP/2，能显著减少延迟
        Ok(peer)
    }

#### **5.3.2 请求过滤器：协议重写 (request\_filter)**

此阶段需要完成三件事：

1. **读取并解析** Claude 格式的 Body。
2. **转换** 为 Gemini 格式的 JSON。
3. **重构** HTTP 请求头（Method, URI, Content-Type, Authorization）。

Rust

    async fn request\_filter(
        &self,
        session: &mut Session,
        ctx: &mut Self::CTX,
    ) \-\> Result\<bool\> {
        // 读取完整的 Request Body (注意：对于超大 Prompt 需谨慎，但通常 Code Prompt 在内存可控范围内)
        // read\_request\_body() 会消耗流，因此我们需要在稍后重新填充 upstream body
        let body\_bytes \= session.read\_request\_body().await?;
        let body\_str \= if let Some(b) \= body\_bytes {
            String::from\_utf8\_lossy(\&b).to\_string()
        } else {
            return Ok(false); // 空包体，不做处理
        };

        // 反序列化 Claude 请求
        let claude\_req: ClaudeRequest \= match serde\_json::from\_str(\&body\_str) {
            Ok(req) \=\> req,
            Err(e) \=\> {
                log::error\!("Failed to parse Claude request: {}", e);
                return Ok(false); // 或者返回 400 错误响应
            }
        };

        // \--- 逻辑转换: 模型映射 \---
        // 用户可能会请求 "claude-3-opus" 或 "claude-3-5-sonnet"
        // 我们将其映射到 Gemini 的等效模型
        ctx.target\_model \= if claude\_req.model.contains("sonnet") |

| claude\_req.model.contains("opus") {
             "gemini-1.5-pro".to\_string()
        } else {
             "gemini-2.0-flash-exp".to\_string() // 使用更快的 Flash 模型作为默认
        };

        // \--- 逻辑转换: 构建 Gemini Body \---
        let mut gemini\_contents \= Vec::new();
        for msg in claude\_req.messages {
            // Role 映射: assistant \-\> model
            let role \= if msg.role \== "assistant" { "model" } else { "user" };

            // Content 提取: 处理字符串或块
            let text \= match msg.content {
                ContentType::Text(t) \=\> t,
                ContentType::Blocks(blocks) \=\> blocks.into\_iter()
                   .filter(|b| b.block\_type \== "text") // 目前仅支持文本，过滤掉图像等
                   .map(|b| b.text.unwrap\_or\_default())
                   .collect::\<Vec\<\_\>\>().join("\\n"),
            };

            gemini\_contents.push(GeminiContent {
                role: role.to\_string(),
                parts: vec\!\[GeminiPart { text }\],
            });
        }

        // System Prompt 转换
        let system\_instruction \= claude\_req.system.map(|sys| GeminiSystemInstruction {
            parts: vec\!\[GeminiPart { text: sys }\]
        });

        let gemini\_req \= GeminiRequest {
            contents: gemini\_contents,
            system\_instruction,
            generation\_config: Some(GeminiGenConfig {
                maxOutputTokens: claude\_req.max\_tokens,
            }),
        };

        // 序列化为 Gemini JSON
        let new\_body\_vec \= serde\_json::to\_vec(\&gemini\_req).unwrap();
        let new\_body\_len \= new\_body\_vec.len();
        let new\_body\_bytes \= Bytes::from(new\_body\_vec);

        // \--- 关键步骤: 修改 Session 以发送新请求 \---

        // 1. 修改 URI
        // Gemini 格式: /v1beta/models/{model}:streamGenerateContent?key={API\_KEY}
        // 使用 streamGenerateContent 以支持 SSE 模拟
        let new\_path \= format\!(
            "/v1beta/models/{}:streamGenerateContent?key={}",
            ctx.target\_model, self.gemini\_token
        );
        session.req\_header\_mut().set\_uri(new\_path.parse().unwrap());

        // 2. 修改 Headers
        session.req\_header\_mut().set\_method("POST");
        session.req\_header\_mut().insert\_header("Content-Type", "application/json").unwrap();
        session.req\_header\_mut().insert\_header("Content-Length", new\_body\_len.to\_string()).unwrap();
        session.req\_header\_mut().insert\_header("Host", "generativelanguage.googleapis.com").unwrap();
        // 移除 Claude 的 x-api-key 以免混淆
        session.req\_header\_mut().remove\_header("x-api-key");

        // 3. 重置 Request Body
        // Pingora 提供了将 body 写回 session 的机制，或者我们需要在 upstream\_request\_body\_filter 中写入
        // 为简化，我们这里直接通过 set\_request\_body (如果 Pingora 版本支持) 或在 ctx 中保存
        // 并在 upstream\_request\_body\_filter 中发送。
        // 这是一个 Pingora 特有的处理模式：如果你读了 body，你负责写回它。

        // 假设我们通过某种机制将 new\_body\_bytes 传递给 upstream\_request\_body\_filter
        // 这里我们可以利用 session 的内部缓冲区重置机制 (verify specific API docs)
        // 或者将 bytes 存入 ctx，然后在下面的 filter 中 drain 出来。

        Ok(false) // 继续处理，不短路
    }

#### **5.3.3 响应体过滤器：流式转换状态机 (response\_body\_filter)**

这是最具挑战性的部分。我们需要将 Gemini 的 \[{...},{...}\] 转换为 Claude 的 SSE 格式。

* **Gemini 流特征**：首个字符是 \[。随后的每个 Chunk 可能以 , 开头。最后一个字符是 \]。
* **解析策略**：
  1. 累积 Bytes 到 ctx.response\_buffer。
  2. 扫描缓冲区，寻找完整的 JSON 对象。由于 JSON 对象包含嵌套的大括号，我们不能简单地按 } 分割，必须使用计数器（Counter）算法来匹配 { 和 }。
  3. 每发现一个完整对象，将其切割（Drain），反序列化，生成 SSE，然后继续扫描。

Rust

    async fn response\_body\_filter(
        &self,
        \_session: &mut Session,
        body: &mut Option\<Bytes\>,
        \_end\_of\_stream: bool,
        ctx: &mut Self::CTX,
    ) \-\> Result\<Option\<std::time::Duration\>\> {
        // 1. 将新收到的数据追加到 buffer
        if let Some(chunk) \= body.take() {
            ctx.response\_buffer.extend\_from\_slice(\&chunk);
        }

        let mut outgoing\_data \= BytesMut::new();

        // 2. 状态机解析循环
        loop {
            // 移除前导的空白、逗号或左方括号 '\[' (Gemini 数组的开始)
            while\!ctx.response\_buffer.is\_empty() {
                let b \= ctx.response\_buffer;
                if b \== b'\[' |

| b \== b',' |
| b.is\_ascii\_whitespace() {
                    ctx.response\_buffer.advance(1);
                } else {
                    break;
                }
            }

            if ctx.response\_buffer.is\_empty() {
                break;
            }

            // 检查是否是数组结束符 '\]'
            if ctx.response\_buffer \== b'\]' {
                ctx.response\_buffer.advance(1);
                // 流结束
                continue;
            }

            // 尝试寻找一个完整的 JSON 对象
            // 算法：从 buffer 开头开始，计数 '{' \+1, '}' \-1。当计数归零且非零开始时，为一个对象。
            let mut brace\_count \= 0;
            let mut split\_idx \= None;
            let mut in\_string \= false;
            let mut escaped \= false;

            for (i, \&b) in ctx.response\_buffer.iter().enumerate() {
                if in\_string {
                    if escaped {
                        escaped \= false;
                    } else if b \== b'\\\\' {
                        escaped \= true;
                    } else if b \== b'"' {
                        in\_string \= false;
                    }
                } else {
                    if b \== b'"' {
                        in\_string \= true;
                    } else if b \== b'{' {
                        brace\_count \+= 1;
                    } else if b \== b'}' {
                        brace\_count \-= 1;
                        if brace\_count \== 0 {
                            split\_idx \= Some(i \+ 1);
                            break;
                        }
                    }
                }
            }

            // 3. 如果找到了完整的 JSON 对象，进行提取和转换
            if let Some(len) \= split\_idx {
                let json\_bytes \= ctx.response\_buffer.split\_to(len);

                // 反序列化
                if let Ok(gemini\_chunk) \= serde\_json::from\_slice::\<GeminiResponseChunk\>(\&json\_bytes) {

                    // A. 如果是流的开始，发送 message\_start
                    if\!ctx.header\_sent {
                        let msg\_start \= format\!(
                            "event: message\_start\\ndata: {}\\n\\n",
                            serde\_json::json\!({
                                "type": "message\_start",
                                "message": {
                                    "id": "msg\_simulated\_gemini",
                                    "type": "message",
                                    "role": "assistant",
                                    "model": ctx.target\_model,
                                    "usage": {"input\_tokens": 0, "output\_tokens": 0} // 初始 Usage 占位
                                }
                            })
                        );
                        outgoing\_data.put(msg\_start.as\_bytes());

                        let content\_start \= format\!(
                            "event: content\_block\_start\\ndata: {}\\n\\n",
                            serde\_json::json\!({
                                "type": "content\_block\_start",
                                "index": 0,
                                "content\_block": {"type": "text", "text": ""}
                            })
                        );
                        outgoing\_data.put(content\_start.as\_bytes());

                        ctx.header\_sent \= true;
                    }

                    // B. 提取文本 Delta 并发送 content\_block\_delta
                    if let Some(candidates) \= gemini\_chunk.candidates {
                        if let Some(first\_candidate) \= candidates.first() {
                            if let Some(content) \= \&first\_candidate.content {
                                for part in \&content.parts {
                                    // 只有当 text 不为空时才发送
                                    if\!part.text.is\_empty() {
                                        // 手动构造 SSE JSON 以避免不必要的序列化开销
                                        // 注意: 必须对 text 进行 JSON 转义
                                        let delta\_json \= serde\_json::json\!({
                                            "type": "content\_block\_delta",
                                            "index": 0,
                                            "delta": {
                                                "type": "text\_delta",
                                                "text": part.text
                                            }
                                        });

                                        let sse\_event \= format\!("event: content\_block\_delta\\ndata: {}\\n\\n", delta\_json);
                                        outgoing\_data.put(sse\_event.as\_bytes());
                                    }
                                }
                            }

                            // C. 检查 FinishReason，如果结束，发送停止事件
                            if first\_candidate.finishReason.is\_some() {
                                let block\_stop \= "event: content\_block\_stop\\ndata: {\\"type\\": \\"content\_block\_stop\\", \\"index\\": 0}\\n\\n";
                                outgoing\_data.put(block\_stop.as\_bytes());

                                let msg\_delta \= "event: message\_delta\\ndata: {\\"type\\": \\"message\_delta\\", \\"delta\\": {\\"stop\_reason\\": \\"end\_turn\\", \\"stop\_sequence\\": null}, \\"usage\\": {\\"output\_tokens\\": 0}}\\n\\n";
                                outgoing\_data.put(msg\_delta.as\_bytes());

                                let msg\_stop \= "event: message\_stop\\ndata: {\\"type\\": \\"message\_stop\\"}\\n\\n";
                                outgoing\_data.put(msg\_stop.as\_bytes());
                            }
                        }
                    }
                } else {
                    log::warn\!("Skipping invalid JSON chunk from Gemini stream");
                }
            } else {
                // 没有找到完整的 JSON 对象，说明数据被截断。
                // 停止处理，等待下一个网络包（Chunk）到来。
                // 数据保留在 ctx.response\_buffer 中。
                break;
            }
        }

        // 4. 将转换后的 SSE 数据写入下游
        if\!outgoing\_data.is\_empty() {
            \*body \= Some(outgoing\_data.freeze());
        }

        Ok(None)
    }
}

---

## **6. 高级特性与生产环境考量 (Advanced Topics)**

### **6.1 Kimi k2 与 "Thinking" 模型的兼容性**

报告中提到的 "Kimi k2" 以及最新的 "Gemini 2.0 Flash Thinking" 模型引入了 "Reasoning"（推理/思考）阶段。Claude Code 目前可能并未针对 "Thinking" 区块进行专门的 UI 渲染，或者它期望通过标准的文本流接收所有内容。

* **挑战**：如果 Gemini 返回一个类型为 reasoning 的 part，而不是 text part。
* **策略**：代理应检测 part 的元数据。为了最大化兼容性，建议将 Gemini 的 reasoning 内容也作为标准的 text\_delta 发送给 Claude Code，并在文本前加上 \\n 的标记，或者选择将其过滤掉（如果用户只想要结果）。考虑到 Claude Code 是 CLI 工具，将思考过程打印出来通常是有益的。

### **6.2 错误处理 (Error Handling)**

如果 Google API 返回错误（如 429 Quota Exceeded 或 400 Bad Request），它通常不会返回流式 JSON 数组，而是直接返回一个标准的 JSON 错误对象 13。

Pingora 的 response\_body\_filter 必须具备嗅探能力：

1. 检查 session.upstream\_response() 的状态码。如果非 200 OK，则不进入流式解析逻辑。
2. 读取完整的错误 Body。
3. 将其转换为 Anthropic 的错误格式：
   JSON
   {
     "type": "error",
     "error": {
       "type": "invalid\_request\_error",
       "message": "Gemini Error: \[Google Message Here\]"
     }
   }

如果不做此转换，Claude Code 客户端在解析 SSE 时会遇到非 SSE 格式的 JSON，直接抛出 JSONDecodeError 并崩溃，导致用户无法看到真实的错误原因。

### **6.3 安全性：API Token 透传**

本设计中，用户直接提供 Gemini Token。这简化了密钥管理（Key Management System, KMS）的需求。代理本身是无状态的（Stateless），不存储任何 Key。

* **风险**：Gemini Token 在 x-goog-api-key 中明文传输（虽然有 TLS 保护）。
* **缓解**：确保代理服务仅通过 HTTPS 暴露，并且在日志中通过 Pingora 的日志过滤器脱敏（Redact）URL 中的 key 参数和 Header 中的 Token。

### **6.4 性能优化：Zero-Copy 与 BytesMut**

在 Rust 实现中，使用了 bytes::BytesMut。这是一个关键的性能优化点。

* **机制**：BytesMut 允许我们在堆上预分配一块连续内存。当 Pingora 接收到新的 TCP 数据包时，我们直接将其 extend 到这块内存的尾部，而不需要创建新的 Vec\<u8\>。
* **优势**：减少了内存分配器（Allocator）的压力，特别是在高并发的流式处理场景下，这能显著降低延迟抖动（Jitter）。

---

## **7. 结论 (Conclusion)**

本报告详细论证了使用 Rust 和 Pingora 构建 Claude-to-Gemini 协议代理的可行性与优越性。通过深入分析 HTTP/2 协议细节、JSON 流式解析算法以及 SSE 事件合成逻辑，我们展示了一个能够欺骗 Claude Code 客户端、使其无缝对接 Google 高性能模型的系统设计。

该架构不仅解决了当前的 API 兼容性问题，其模块化的 Filter 设计也为未来集成其他模型（如 OpenAI o1 或 DeepSeek）留下了扩展接口。对于追求极致开发效率与成本控制的工程团队而言，这种基于 Pingora 的中间件方案代表了 LLM 基础设施演进的一个重要方向：从单一供应商绑定走向多模型路由与编排。

### **数据引用**

* 2 Anthropic API Specification (Requests & SSE).
* 1 Google Gemini API Specification (REST & Streaming).
* 3 Pingora Framework Documentation (Filters & Traits).
* 15 Community findings on Gemini streaming behaviors.

#### **Works cited**

1. Generating content | Gemini API \- Google AI for Developers, accessed November 18, 2025, [https://ai.google.dev/api/generate-content](https://ai.google.dev/api/generate-content)
2. Messages \- Claude Docs, accessed November 18, 2025, [https://docs.anthropic.com/en/api/messages](https://docs.anthropic.com/en/api/messages)
3. Examples: taking control of the request – PingoraRust.COM, accessed November 18, 2025, [https://www.pingorarust.com/user\_guide/modify\_filter](https://www.pingorarust.com/user_guide/modify_filter)
4. Open sourcing Pingora: our Rust framework for building programmable network services, accessed November 18, 2025, [https://blog.cloudflare.com/pingora-open-source/](https://blog.cloudflare.com/pingora-open-source/)
5. Life of a request: pingora-proxy phases and filters – PingoraRust.COM, accessed November 18, 2025, [https://www.pingorarust.com/user\_guide/phase](https://www.pingorarust.com/user_guide/phase)
6. Messages \- Claude Docs, accessed November 18, 2025, [https://docs.claude.com/en/api/messages](https://docs.claude.com/en/api/messages)
7. Gemini API reference | Google AI for Developers, accessed November 18, 2025, [https://ai.google.dev/api](https://ai.google.dev/api)
8. Using the Messages API \- Claude Docs, accessed November 18, 2025, [https://docs.claude.com/en/docs/build-with-claude/working-with-messages](https://docs.claude.com/en/docs/build-with-claude/working-with-messages)
9. Request and Response \- Amazon Bedrock \- AWS Documentation, accessed November 18, 2025, [https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages-request-response.html](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages-request-response.html)
10. Method: models.streamGenerateContent | Generative AI on Vertex AI \- Google Cloud, accessed November 18, 2025, [https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1beta1/projects.locations.publishers.models/streamGenerateContent](https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1beta1/projects.locations.publishers.models/streamGenerateContent)
11. Generate content with the Gemini API in Vertex AI \- Google Cloud Documentation, accessed November 18, 2025, [https://docs.cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference](https://docs.cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference)
12. GenerateContentResponse | Generative AI on Vertex AI | Google Cloud Documentation, accessed November 18, 2025, [https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1/GenerateContentResponse](https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1/GenerateContentResponse)
13. \#\#\# Bug Report: \`json.loads(chunk)\` fails on Gemini streaming error message · Issue \#1162 · googleapis/python-genai \- GitHub, accessed November 18, 2025, [https://github.com/googleapis/python-genai/issues/1162](https://github.com/googleapis/python-genai/issues/1162)
14. ProxyHttp in pingora::prelude \- Rust \- Docs.rs, accessed November 18, 2025, [https://docs.rs/pingora/latest/pingora/prelude/trait.ProxyHttp.html](https://docs.rs/pingora/latest/pingora/prelude/trait.ProxyHttp.html)
15. Truncated Response Issue with Gemini 2.5 Flash Preview \- Google AI Developers Forum, accessed November 18, 2025, [https://discuss.ai.google.dev/t/truncated-response-issue-with-gemini-2-5-flash-preview/81258?page=2](https://discuss.ai.google.dev/t/truncated-response-issue-with-gemini-2-5-flash-preview/81258?page=2)
16. \[Bug\]: Query Engine gives incomplete streaming response when using Gemini LLMs · Issue \#13684 · run-llama/llama\_index \- GitHub, accessed November 18, 2025, [https://github.com/run-llama/llama\_index/issues/13684](https://github.com/run-llama/llama_index/issues/13684)
